# Building a Custom Analytics App with MongoDB + Node.js + ChatGPT
## Architecture Tutorial & Template

### Overview
This tutorial explains how to build a natural language analytics system using:
- MongoDB for data storage
- Node.js for backend API
- ChatGPT as the user interface
- OpenAI API for query processing

Key Feature: Users interact with their data through natural language in ChatGPT, no traditional web frontend needed.

### Project Structure
project_root/
├── .env                    # Environment variables
├── .env.example           # Environment template
├── index.js               # Main server file
├── package.json           # Dependencies
├── routes/
│   └── chat.js           # Main API route
├── models/
│   └── event.js          # MongoDB schema
└── config/
    ├── instructions.txt   # ChatGPT instructions
    └── master_list.json   # Field definitions

### Step-by-Step Setup

1. Environment Setup
npm init
npm install express mongoose dotenv openai cors

2. Environment Variables (.env)
MONGODB_URI=mongodb://localhost:27017/your_database
OPENAI_API_KEY=your-openai-key
PORT=3000

3. MongoDB Schema (models/event.js)
const mongoose = require('mongoose');

const eventSchema = new mongoose.Schema({
  // Define your fields here
  // Example:
  name: String,
  timestamp: Date,
  metrics: {
    type: Map,
    of: mongoose.Schema.Types.Mixed
  }
}, { strict: false });

module.exports = mongoose.model('Event', eventSchema);

4. API Route (routes/chat.js)
const express = require('express');
const router = express.Router();
const OpenAI = require('openai');
const Event = require('../models/event');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

router.post('/query', async (req, res) => {
  try {
    // 1. Parse natural language query
    const analysis = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        {
          role: "system",
          content: "Convert natural language to MongoDB query"
        },
        {
          role: "user",
          content: req.body.message
        }
      ]
    });

    // 2. Execute MongoDB query
    const data = await Event.find(analysis.query);

    // 3. Format response
    const response = {
      data,
      explanation: analysis.explanation,
      suggestions: analysis.suggestions
    };

    res.json(response);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;

5. Server Setup (index.js)
require('dotenv').config();
const express = require('express');
const mongoose = require('mongoose');
const cors = require('cors');
const chatRoute = require('./routes/chat');

const app = express();

mongoose.connect(process.env.MONGODB_URI);

app.use(cors());
app.use(express.json());
app.use('/chat', chatRoute);

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});

### Advanced Features

1. Real-time Query Clarification
// In chat.js route
const clarification = await openai.chat.completions.create({
  messages: [
    {
      role: "system",
      content: "Check if query needs clarification"
    },
    {
      role: "user",
      content: req.body.message
    }
  ]
});

if (clarification.needsClarification) {
  return res.json({
    needsClarification: true,
    questions: clarification.questions
  });
}

2. Automated Reports
async function generateReport(startDate, endDate) {
  const data = await Event.find({
    timestamp: {
      $gte: startDate,
      $lte: endDate
    }
  });

  return {
    period: `${startDate} to ${endDate}`,
    metrics: calculateMetrics(data),
    trends: analyzeTrends(data),
    recommendations: generateRecommendations(data)
  };
}

3. Budget Forecasting
async function generateForecast(months = 3) {
  const historicalData = await Event.find({
    timestamp: {
      $gte: new Date(Date.now() - 90 * 24 * 60 * 60 * 1000)
    }
  });

  return {
    projections: calculateProjections(historicalData),
    recommendations: forecastRecommendations(historicalData)
  };
}

### ChatGPT Integration

1. Create a new GPT in ChatGPT
2. Upload your field definitions (master_list.json)
3. Set system instructions:
You are an analytics assistant that helps users query their data.
Backend API endpoint: http://localhost:3000/chat/query
Available fields: [list from master_list.json]

### Customization Guide

1. Define Your Schema
   - Map your data structure to MongoDB
   - Create a master list of fields
   - Define metrics and calculations

2. Customize Analysis
   - Add domain-specific calculations
   - Define relevant trends and patterns
   - Create custom recommendations

3. Enhance ChatGPT Prompts
   - Add domain expertise to system prompt
   - Define common query patterns
   - Add clarification strategies

### Best Practices

1. Data Structure
   - Use flexible schemas for analytics
   - Index frequently queried fields
   - Consider time-series optimizations

2. API Design
   - Implement rate limiting
   - Add error handling
   - Cache common queries
   - Use pagination for large datasets

3. Security
   - Validate all inputs
   - Sanitize MongoDB queries
   - Implement API authentication
   - Secure environment variables

### Testing

1. Backend Testing
npm install jest supertest --save-dev

2. Sample Test
describe('Chat API', () => {
  it('should handle natural language queries', async () => {
    const response = await request(app)
      .post('/chat/query')
      .send({ message: 'Show me recent data' });
    expect(response.status).toBe(200);
    expect(response.body).toHaveProperty('data');
  });
});

### Common Issues & Solutions

1. MongoDB Connection
   - Verify connection string
   - Check database permissions
   - Ensure proper indexes

2. OpenAI API
   - Validate API key
   - Handle rate limits
   - Implement fallback logic

3. Query Processing
   - Validate generated queries
   - Handle edge cases
   - Implement query timeout

### Maintenance

1. Regular Tasks
   - Update dependencies
   - Monitor API usage
   - Backup database
   - Review error logs

2. Performance
   - Monitor query times
   - Optimize indexes
   - Cache hot data
   - Clean old data

### Scaling

1. Database
   - Implement sharding
   - Add replicas
   - Use connection pooling

2. API
   - Add load balancing
   - Implement caching
   - Use worker threads

### Next Steps

1. Add authentication
2. Implement data validation
3. Add visualization support
4. Set up monitoring
5. Add backup system

This template provides a foundation for building any analytics system with natural language interface. Customize the data model and analysis logic for your specific use case while maintaining this architecture.
